from litellm import completion

# ä½¿ç”¨ LiteLLM çš„æ¨¡å‹æ ¼å¼ï¼Œå»ºè­°ä¸­æ–‡æ¨¡å‹å¦‚ qwen2.5:7b
MODEL = "ollama/qwen2.5:7b"
BASE_URL = "http://localhost:11434"

def infer_emotion_llm(user_input: str) -> str:
    """
    ä½¿ç”¨ LLM æ¨è«–æƒ…ç·’ï¼Œåªå›å‚³å–®ä¸€æƒ…ç·’é¡åˆ¥
    """
    prompt = f"""
è«‹åˆ¤æ–·ä¸‹åˆ—å¥å­çš„æƒ…ç·’ï¼Œåªå›å‚³å–®ä¸€æƒ…ç·’é¡åˆ¥ï¼ˆä¸è¦å¤šé¤˜æè¿°ï¼‰ï¼š

å¯ç”¨æƒ…ç·’é¡åˆ¥ï¼š
é–‹å¿ƒ ğŸ˜„ã€æ‚²å‚· ğŸ˜¢ã€ç”Ÿæ°£ ğŸ˜ ã€é©šè¨ ğŸ˜²ã€å®³ç¾ ğŸ™ˆã€ç„¡èŠ ğŸ˜ã€ç·Šå¼µ ğŸ˜°ã€ä¸­ç«‹ ğŸ˜¶

å¥å­ï¼šã€Œ{user_input}ã€
å›ç­”ï¼š
""".strip()

    try:
        response = completion(
            model=MODEL,
            messages=[{"role": "user", "content": prompt}],
            base_url=BASE_URL,
        )
        result = response["choices"][0]["message"]["content"].strip()
        return result if result else "ä¸­ç«‹ ğŸ˜¶"
    except Exception:
        return "ä¸­ç«‹ ğŸ˜¶"

import os
from typing import Final

import requests

# ä½¿ç”¨ Ollama ä¾†åˆ¤æ–·æƒ…ç·’ï¼Œé è¨­èµ°æœ¬æ©Ÿç«¯é»ï¼Œå¿…è¦æ™‚å¯é€éç’°å¢ƒè®Šæ•¸è¦†è“‹
EMOTION_MODEL: Final[str] = os.environ.get("OLLAMA_EMOTION_MODEL", "qwen2.5:7b")
OLLAMA_BASE_URL: Final[str] = os.environ.get(
    "OLLAMA_BASE_URL", "http://localhost:11434"
)
OLLAMA_GENERATE_URL: Final[str] = f"{OLLAMA_BASE_URL.rstrip('/')}/api/generate"

def infer_emotion_llm(user_input: str) -> str:
    """
    ä½¿ç”¨ LLM æ¨è«–æƒ…ç·’ï¼Œåªå›å‚³å–®ä¸€æƒ…ç·’é¡åˆ¥ã€‚

    æ”¹ç”¨ç›´æ¥å‘¼å« Ollamaï¼Œé¿å… LiteLLM é€£ç·šéŒ¯èª¤å½±éŸ¿å‰ç«¯é«”é©—ã€‚
    """
    prompt = f"""
è«‹åˆ¤æ–·ä¸‹åˆ—å¥å­çš„æƒ…ç·’ï¼Œåªå›å‚³å–®ä¸€æƒ…ç·’é¡åˆ¥ï¼ˆä¸è¦å¤šé¤˜æè¿°ï¼‰ï¼š

å¯ç”¨æƒ…ç·’é¡åˆ¥ï¼š
é–‹å¿ƒ ğŸ˜„ã€æ‚²å‚· ğŸ˜¢ã€ç”Ÿæ°£ ğŸ˜ ã€é©šè¨ ğŸ˜²ã€å®³ç¾ ğŸ™ˆã€ç„¡èŠ ğŸ˜ã€ç·Šå¼µ ğŸ˜°ã€ä¸­ç«‹ ğŸ˜¶

å¥å­ï¼šã€Œ{user_input}ã€
å›ç­”ï¼š
""".strip()
    payload = {"model": EMOTION_MODEL, "prompt": prompt, "stream": False}

    try:
        response = requests.post(OLLAMA_GENERATE_URL, json=payload, timeout=30)
        response.raise_for_status()
        data = response.json()
        result = data.get("response", "").strip()
        
        return result if result else "ä¸­ç«‹ ğŸ˜¶"
    except Exception:
        return "ä¸­ç«‹ ğŸ˜¶"
